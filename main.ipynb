{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54195858",
   "metadata": {},
   "source": [
    "# E-Commerce Sales Data Warehouse & Analysis\n",
    "\n",
    "Ez a Jupyter Notebook bemutatja az OLTP ‚Üí DWH ‚Üí Elemz√©s folyamatot a Brazilian E-Commerce Public Dataset by Olist alapj√°n.\n",
    "\n",
    "**F≈ë l√©p√©sek:**\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8654ba44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè≠ Az SQLite adatt√°rh√°z elk√©sz√ºlt, dimenzi√≥k replace √©s fact append m√≥dban bet√∂ltve.\n"
     ]
    }
   ],
   "source": [
    "# 1) modulok import√°l√°sa\n",
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "\n",
    "# 2) CSV-k beolvas√°sa a helyes sep/encoding param√©terekkel\n",
    "data_dir = \"./\"    # a notebook √©s a CSV-k ugyanabban a mapp√°ban vannak\n",
    "dfs = {}\n",
    "\n",
    "# 2a) Translation f√°jl (fix be√°ll√≠t√°s)\n",
    "dfs['translation'] = pd.read_csv(\n",
    "    os.path.join(data_dir, \"product_category_name_translation.csv\"),\n",
    "    sep=\";\", encoding=\"latin1\", engine=\"python\"\n",
    ")\n",
    "\n",
    "# 2b) CUSTOMERS ‚Äî Python‚Äêmotor, id√©z≈ëkarakter, hib√°s sorok √°tugr√°sa\n",
    "dfs['customers'] = pd.read_csv(\n",
    "    os.path.join(data_dir, \"olist_customers_dataset.csv\"),\n",
    "    sep=\",\", encoding=\"latin1\", engine=\"python\",\n",
    "    quotechar='\"', on_bad_lines=\"warn\", dtype=str\n",
    ")\n",
    "assert 'customer_id' in dfs['customers'].columns, \"Nincs customer_id az oszlopok k√∂z√∂tt!\"\n",
    "dfs['customers'] = dfs['customers'].drop_duplicates(\"customer_id\").reset_index(drop=True)\n",
    "dfs['customers']['customer_key'] = dfs['customers'].index + 1\n",
    "\n",
    "# 2c) A t√∂bbi 7 f√°jl (alapesetben UTF-8, ha kell fallback)\n",
    "files = {\n",
    "    'geolocation':     \"olist_geolocation_dataset.csv\",\n",
    "    'order_items':     \"olist_order_items_dataset.csv\",\n",
    "    'order_payments':  \"olist_order_payments_dataset.csv\",\n",
    "    'order_reviews':   \"olist_order_reviews_dataset.csv\",\n",
    "    'orders':          \"olist_orders_dataset.csv\",\n",
    "    'products':        \"olist_products_dataset.csv\",\n",
    "    'sellers':         \"olist_sellers_dataset.csv\",\n",
    "}\n",
    "\n",
    "for name, fname in files.items():\n",
    "    path = os.path.join(data_dir, fname)\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=\",\", encoding=\"utf-8\")\n",
    "    except (UnicodeDecodeError, ParserError):\n",
    "        df = pd.read_csv(path, sep=\"\\t\", encoding=\"latin1\", engine=\"python\")\n",
    "    dfs[name] = df\n",
    "\n",
    "# 3) Surrogate kulcsok √©s dimenzi√≥k el≈ë√°ll√≠t√°sa\n",
    "\n",
    "# --- Dim_Date\n",
    "dates = pd.to_datetime(dfs['orders']['order_purchase_timestamp'], errors='coerce')\n",
    "dates = (\n",
    "    dates.dropna().drop_duplicates().to_frame(name='full_date')\n",
    "         .assign(\n",
    "             year=lambda d: d['full_date'].dt.year,\n",
    "             month=lambda d: d['full_date'].dt.month,\n",
    "             day=lambda d: d['full_date'].dt.day,\n",
    "             day_of_week=lambda d: d['full_date'].dt.dayofweek+1,\n",
    "             quarter=lambda d: d['full_date'].dt.quarter\n",
    "         )\n",
    "         .sort_values('full_date').reset_index(drop=True)\n",
    ")\n",
    "dates['date_key'] = dates.index + 1\n",
    "\n",
    "# --- Dim_Product\n",
    "prod = (\n",
    "    dfs['products'][[\n",
    "        'product_id','product_category_name',\n",
    "        'product_name_lenght','product_description_lenght'\n",
    "    ]]\n",
    "    .drop_duplicates('product_id').reset_index(drop=True)\n",
    "    .rename(columns={\n",
    "        'product_name_lenght': 'product_name_length',\n",
    "        'product_description_lenght': 'product_description_len'\n",
    "    })\n",
    ")\n",
    "prod['product_key'] = prod.index + 1\n",
    "\n",
    "# --- Dim_Seller\n",
    "sell = (\n",
    "    dfs['sellers'][[\n",
    "        'seller_id','seller_zip_code_prefix','seller_city','seller_state'\n",
    "    ]]\n",
    "    .drop_duplicates('seller_id').reset_index(drop=True)\n",
    ")\n",
    "sell['seller_key'] = sell.index + 1\n",
    "\n",
    "# --- Dim_Payment\n",
    "pay = (\n",
    "    dfs['order_payments'][[\n",
    "        'order_id','payment_sequential','payment_type','payment_installments'\n",
    "    ]]\n",
    "    .drop_duplicates(['order_id','payment_sequential']).reset_index(drop=True)\n",
    ")\n",
    "pay['payment_key'] = pay.index + 1\n",
    "\n",
    "# 4) Fact_Sales √∂ssze√°ll√≠t√°sa\n",
    "oi = dfs['order_items']\n",
    "o  = dfs['orders']\n",
    "fact = (\n",
    "    oi\n",
    "     .merge(o[['order_id','customer_id','order_purchase_timestamp']], on='order_id', how='left')\n",
    "     .merge(prod[['product_id','product_key']], on='product_id', how='left')\n",
    "     .merge(dfs['customers'][['customer_id','customer_key']], on='customer_id', how='left')\n",
    "     .merge(sell[['seller_id','seller_key']], on='seller_id', how='left')\n",
    "     .merge(pay[['order_id','payment_key']], on='order_id', how='left')\n",
    ")\n",
    "\n",
    "fact['order_purchase_timestamp'] = pd.to_datetime(fact['order_purchase_timestamp'])\n",
    "fact = fact.merge(\n",
    "    dates[['full_date','date_key']],\n",
    "    left_on='order_purchase_timestamp', right_on='full_date', how='left'\n",
    ")\n",
    "\n",
    "fact = fact.assign(\n",
    "    quantity      = fact['order_item_id'],\n",
    "    price         = fact['price'],\n",
    "    freight_value = fact['freight_value']\n",
    ")\n",
    "fact['total_amount'] = fact['price']*fact['quantity'] + fact['freight_value']\n",
    "\n",
    "fact = fact[[\n",
    "    'order_id','product_key','customer_key','seller_key',\n",
    "    'date_key','payment_key',\n",
    "    'quantity','price','freight_value','total_amount'\n",
    "]]\n",
    "\n",
    "# 5) SQLite adatb√°zis √©s t√°bl√°k l√©trehoz√°sa, bet√∂lt√©s\n",
    "conn = sqlite3.connect('ecommerce_dwh.sqlite')\n",
    "cur = conn.cursor()\n",
    "cur.executescript(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Dim_Date (\n",
    "  date_key INTEGER PRIMARY KEY,\n",
    "  full_date TEXT, year INTEGER, month INTEGER,\n",
    "  day INTEGER, day_of_week INTEGER, quarter INTEGER\n",
    ");\n",
    "CREATE TABLE IF NOT EXISTS Dim_Product (\n",
    "  product_key INTEGER PRIMARY KEY,\n",
    "  product_id TEXT, product_category_name TEXT,\n",
    "  product_name_length INTEGER, product_description_len INTEGER\n",
    ");\n",
    "CREATE TABLE IF NOT EXISTS Dim_Customer (\n",
    "  customer_key INTEGER PRIMARY KEY,\n",
    "  customer_id TEXT, customer_unique_id TEXT,\n",
    "  zip_code_prefix TEXT, city TEXT, state TEXT\n",
    ");\n",
    "CREATE TABLE IF NOT EXISTS Dim_Seller (\n",
    "  seller_key INTEGER PRIMARY KEY,\n",
    "  seller_id TEXT, zip_code_prefix TEXT, city TEXT, state TEXT\n",
    ");\n",
    "CREATE TABLE IF NOT EXISTS Dim_Payment (\n",
    "  payment_key INTEGER PRIMARY KEY,\n",
    "  order_id TEXT, payment_type TEXT, payment_installments INTEGER\n",
    ");\n",
    "CREATE TABLE IF NOT EXISTS Fact_Sales (\n",
    "  sales_key     INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "  order_id      TEXT, product_key INTEGER,\n",
    "  customer_key  INTEGER, seller_key INTEGER,\n",
    "  date_key      INTEGER, payment_key INTEGER,\n",
    "  quantity      INTEGER, price REAL,\n",
    "  freight_value REAL, total_amount REAL,\n",
    "  FOREIGN KEY(product_key)  REFERENCES Dim_Product(product_key),\n",
    "  FOREIGN KEY(customer_key) REFERENCES Dim_Customer(customer_key),\n",
    "  FOREIGN KEY(seller_key)   REFERENCES Dim_Seller(seller_key),\n",
    "  FOREIGN KEY(date_key)     REFERENCES Dim_Date(date_key),\n",
    "  FOREIGN KEY(payment_key)  REFERENCES Dim_Payment(payment_key)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# ‚Äî Dimenzi√≥k fel√ºl√≠r√°sa replace m√≥dban ‚Äî \n",
    "dates.to_sql   ('Dim_Date',    conn, if_exists='replace', index=False)\n",
    "prod.to_sql    ('Dim_Product', conn, if_exists='replace', index=False)\n",
    "\n",
    "cust_df = dfs['customers'][[\n",
    "    'customer_id','customer_unique_id',\n",
    "    'customer_zip_code_prefix','customer_city','customer_state','customer_key'\n",
    "]].rename(columns={\n",
    "    'customer_zip_code_prefix': 'zip_code_prefix',\n",
    "    'customer_city': 'city',\n",
    "    'customer_state': 'state'\n",
    "})\n",
    "cust_df.to_sql('Dim_Customer', conn, if_exists='replace', index=False)\n",
    "\n",
    "sell_df = sell.rename(columns={\n",
    "    'seller_zip_code_prefix': 'zip_code_prefix',\n",
    "    'seller_city':            'city',\n",
    "    'seller_state':           'state'\n",
    "})[[\n",
    "    'seller_id','zip_code_prefix','city','state','seller_key'\n",
    "]]\n",
    "sell_df.to_sql('Dim_Seller', conn, if_exists='replace', index=False)\n",
    "\n",
    "pay[['order_id','payment_type','payment_installments','payment_key']] \\\n",
    "    .to_sql('Dim_Payment', conn, if_exists='replace', index=False)\n",
    "\n",
    "# ‚Äî Fact t√°bla append m√≥dban ‚Äî\n",
    "fact.to_sql  ('Fact_Sales',  conn, if_exists='append', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(\"üè≠ Az SQLite adatt√°rh√°z elk√©sz√ºlt, dimenzi√≥k replace √©s fact append m√≥dban bet√∂ltve.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
